{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4baf809a",
   "metadata": {},
   "source": [
    "## 4. Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca738c",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93840f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805a952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.reset_option('max_rows')\n",
    "# pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a1bdc7",
   "metadata": {},
   "source": [
    "### Convert location to iso2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17b8471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geographical data\n",
    "geo_countries = gpd.read_file('../data/countries.geojson')\n",
    "world_cities = pd.read_csv('../data/worldcities/worldcities.csv', usecols= ['city_ascii', 'country', 'iso2', 'population'])\n",
    "city_iso2 = world_cities.sort_values('population', ascending = False).drop_duplicates('city_ascii').rename(columns={'city_ascii':'city'})[['city', 'iso2']]\n",
    "state_iso2 = pd.read_csv('../data/US_states.csv', usecols=['STATE', 'STATE2']).assign(iso2='USA').rename(columns = {'STATE':'state', 'STATE2':'state2'})\n",
    "country_iso2 = world_cities.sort_values('population', ascending = False).drop_duplicates('iso2')[['country', 'iso2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0286c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace the inconsistent locations with country names\n",
    "US = ['US', 'USA', 'Southern California', 'United States of America', 'West Coast, USA (SEA/GEG/LAX)',\n",
    "       'Democrat in the USA','Washington DC', 'New York City', 'NYC', 'USA (SEA/GEG/LAX)', 'Washington DC',\n",
    "       'Lost in the Minnesota North Woods', 'Washington D.C.', 'U.S.A.', 'U.S.A', 'us', 'New England', 'Philly','D.C.'\n",
    "       ,'usa', 'Northern Virginia', 'American', 'South Florida','Pacific Northwest', 'Northern California', \n",
    "       'San Diego & New Orleans', 'San Francisco Bay Area','New York and the World', 'America','Washington State', \n",
    "       'Midwest','East Coast', 'US of A', 'Harrisburg Pa']\n",
    "UK = ['UK','England', 'Scotland', 'london', 'Wales', 'uk', 'West Saxons', 'LONDON', 'South London', 'Northern Ireland',\n",
    "       'Somerset England UK Eu', 'Derbyshire', 'England and International', 'London UK','Leicestershire','Lancashire'\n",
    "       ,'West Sussex','North Yorkshire','Yorkshire and The Humber, Engl','Yorkshire and The Humber','Newcastle upon Tyne'\n",
    "       ,'Staffordshire','Oxfordshire','Cardiff','West Yorkshire','Cymru','Great Britain','North Wales','Wiltshire'\n",
    "       ,'Stockport','North West England','Cambridgeshire','glasgow','Romford','SCOTLAND','South Wales','Dorset'\n",
    "       ,'some were in UK','england','Hertfordshire','Shropshire England','North East England','Hampshire UK'\n",
    "       ,'Norfolk England','Dorset, England.','Bristol UK','Republic of Wales','U.K.','Lancashire','East Sussex'\n",
    "       ,'Warwickshire', 'Edinburgh ~ Heart of Scotland!']\n",
    "Germany = [\"Deutschland\", 'Somewhere in Germany']\n",
    "Ukraine = ['Ucraina', 'chernivtsi', 'Some Future Place in Ukraine', 'Mariouple']\n",
    "Poland = ['Polska']\n",
    "Canada = ['CANADA']\n",
    "Netherlands = ['The Netherlands']\n",
    "Czechia = ['Czech Republic']\n",
    "Italy = ['Italia']    \n",
    "Brazil = ['Brasil', 'Brazil Brazil']   \n",
    "Finland = ['Suomi', \"East-Finnish People's Republic\"]    \n",
    "Japan = ['Okinotorishima Ogasawara Tokyo']   \n",
    "Australia = ['Queensland','Australia - International']   \n",
    "Sweden = ['Sverige']  \n",
    "Kazakhstan = ['Astana']  \n",
    "Serbia = ['Belgrade City'] \n",
    "India = ['mumbai']   \n",
    "Belgium = ['Belgique', 'Bruxelles']  \n",
    "Ethiopia = ['Tigray']   \n",
    "Venezuela = ['Venezuela revolucionaria']\n",
    "Spain = ['Tarragona']\n",
    "Greece = ['Athens Greece']\n",
    "Denmark = ['Danmark']\n",
    "\n",
    "def convert_loc(text):\n",
    "    if text in US:\n",
    "        return 'United States'\n",
    "    if text in UK:\n",
    "        return 'United Kingdom'\n",
    "    if text in Germany:\n",
    "        return 'Germany'\n",
    "    if text in Ukraine:\n",
    "        return 'Ukraine'\n",
    "    if text in Poland:\n",
    "        return 'Poland'\n",
    "    if text in Canada:\n",
    "        return 'Canada'\n",
    "    if text in Netherlands:\n",
    "        return 'Netherlands'\n",
    "    if text in Czechia:\n",
    "        return 'Czechia'\n",
    "    if text in Italy:\n",
    "        return 'Italy'\n",
    "    if text in Brazil:\n",
    "        return 'Brazil'\n",
    "    if text in Finland:\n",
    "        return 'Finland'\n",
    "    if text in Japan:\n",
    "        return 'Japan'\n",
    "    if text in Australia:\n",
    "        return 'Australia'\n",
    "    if text in Sweden:\n",
    "        return 'Sweden'\n",
    "    if text in Kazakhstan:\n",
    "        return 'Kazakhstan'\n",
    "    if text in Serbia:\n",
    "        return 'Serbia'\n",
    "    if text in India:\n",
    "        return 'India'\n",
    "    if text in Belgium:\n",
    "        return 'Belgium'\n",
    "    if text in Ethiopia:\n",
    "        return 'Ethiopia'\n",
    "    if text in Venezuela:\n",
    "        return 'Venezuela'\n",
    "    if text in Spain:\n",
    "        return 'Spain'\n",
    "    if text in Greece:\n",
    "        return 'Greece'\n",
    "    if text in Denmark:\n",
    "        return 'Denmark'\n",
    "    else:\n",
    "        return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa8d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd4d40e5b58470dbf31a8a1e0b3da88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_to_keep = ['tweet_id', 'acct_desc', 'date', 'location', 'friends_ount','followers_ount', 'text', 'compound', 'iso2_final']\n",
    "for filepath in tqdm(glob.glob('../data/tweets_en/*')):\n",
    "    df = pd.read_csv(filepath, lineterminator='\\n', encoding='latin-1')\n",
    "    \n",
    "    # split the location by comma and assign them to loc1 and loc2 \n",
    "    loc_split = df['location'].apply(lambda x : str(x).split(','))\n",
    "    loc1 = []\n",
    "    loc2 = []\n",
    "    for loc in loc_split:\n",
    "        if len(loc) == 1:\n",
    "            loc1 += [loc[0]]\n",
    "            loc2 += ['nan']\n",
    "        if len(loc) == 2:\n",
    "            loc1 += [loc[0]]\n",
    "            loc2 += [loc[1]]\n",
    "        if len(loc) >2:\n",
    "            loc1 += [loc[0]]\n",
    "            loc2 += [loc[1]]\n",
    "    df = df.assign(loc1 = loc1, loc2 = loc2)\n",
    "    \n",
    "    # strip the blank space in loc1 and loc2; convert the inconsistent loc1 and loc2 to country names\n",
    "    df['loc1'] = df['loc1'].apply(lambda x: x.strip(' '))\n",
    "    df['loc1'] = df['loc1'].apply(convert_loc)\n",
    "    df['loc2'] = df['loc2'].apply(lambda x: x.strip(' '))\n",
    "    df['loc2'] = df['loc2'].apply(convert_loc)\n",
    "    \n",
    "    # merge location columns with iso2 dataframes to match city, state, or country\n",
    "    df = (df.\n",
    "     merge(city_iso2, how = 'left', left_on = 'loc1', right_on = 'city').\n",
    "     merge(city_iso2, how = 'left', left_on = 'loc2', right_on = 'city').\n",
    "     merge(state_iso2, how = 'left', left_on = 'loc1', right_on = 'state').\n",
    "     merge(state_iso2, how = 'left', left_on = 'loc2', right_on = 'state').\n",
    "     merge(state_iso2, how = 'left', left_on = 'loc1', right_on = 'state2').\n",
    "     merge(state_iso2, how = 'left', left_on = 'loc2', right_on = 'state2').\n",
    "     merge(country_iso2, how = 'left', left_on = 'loc1', right_on = 'country').\n",
    "     merge(country_iso2, how = 'left', left_on = 'loc2', right_on = 'country')\n",
    "    )\n",
    "    \n",
    "    # ignore the null values and get the iso2\n",
    "    df['iso2_final'] = (df['iso2_x'].iloc[:,0].\n",
    "     combine_first(df['iso2_x'].iloc[:,1]).\n",
    "     combine_first(df['iso2_x'].iloc[:,2]).\n",
    "     combine_first(df['iso2_x'].iloc[:,3]).\n",
    "     combine_first(df['iso2_y'].iloc[:,0]).\n",
    "     combine_first(df['iso2_y'].iloc[:,1]).\n",
    "     combine_first(df['iso2_y'].iloc[:,2]).\n",
    "     combine_first(df['iso2_y'].iloc[:,3])\n",
    "    )\n",
    "    df = df[col_to_keep]# drop iso2_ columns\n",
    "    df.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743af6d",
   "metadata": {},
   "source": [
    "### Calculate sentiment scores and number of tweets per country before and after the war (2/24/22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc656b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate =pd.to_datetime('2022-02-24').date()\n",
    "keywords = ['ukraine', 'russia', 'eu', 'zelenskyy', 'biden', 'putin', 'johnson', 'nato', 'scholz', 'macron']\n",
    "before_war = pd.DataFrame({'iso2_final':[]}).astype({'iso2_final':'str'})\n",
    "after_war = pd.DataFrame({'iso2_final':[]}).astype({'iso2_final':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5a1ff6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c52d773d1d489cbe1f4320b8ef21dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for keyword in tqdm(keywords):\n",
    "    df = pd.read_csv(f'../data/tweets_en/tweets_{keyword}_en.csv',dtype={'date':'str'}, parse_dates = ['date'], lineterminator='\\n', encoding='latin-1')\n",
    "    df['date'] = pd.DatetimeIndex(df['date']).date\n",
    "    \n",
    "    # before the war\n",
    "    df_temp = (df[(df['date']< startdate)&(abs(df['compound'])>0.1)].\n",
    "                  groupby('iso2_final').\n",
    "                  mean()[['compound']].\n",
    "                  reset_index().\n",
    "                  rename(columns={'compound':f'compound_{keyword}_before_war'}))\n",
    "    df_temp[f'compound_{keyword}_before_war_count'] = (df[(df['date']< startdate)&(abs(df['compound'])>0.1)].\n",
    "            groupby('iso2_final').\n",
    "            count()['compound']).to_list()\n",
    "    before_war = before_war.merge(df_temp, how='outer', left_on='iso2_final', right_on='iso2_final')\n",
    "    \n",
    "    # after the war\n",
    "    df_temp = (df[(df['date']> startdate)&(abs(df['compound'])>0.1)].\n",
    "                  groupby('iso2_final').\n",
    "                  mean()[['compound']].\n",
    "                  reset_index().\n",
    "                  rename(columns={'compound':f'compound_{keyword}_after_war'}))\n",
    "    df_temp[f'compound_{keyword}_after_war_count'] = (df[(df['date']> startdate)&(abs(df['compound'])>0.1)].\n",
    "            groupby('iso2_final').\n",
    "            count()['compound']).to_list()\n",
    "    after_war = after_war.merge(df_temp, how='outer', left_on='iso2_final', right_on='iso2_final')\n",
    "    \n",
    "df_temp = before_war.merge(after_war, how='outer', left_on='iso2_final', right_on='iso2_final')\n",
    "df_temp.dropna(axis='columns', how='all').to_csv('../shinyapp/data/sentiment_per_country.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0ea32",
   "metadata": {},
   "source": [
    "### Calculate sentiment scores and number of tweets per date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_per_date = pd.DataFrame()\n",
    "for keyword in tqdm(keywords):\n",
    "    df = pd.read_csv(f'../data/tweets_en/tweets_{keyword}_en.csv',dtype={'date':'str'}, parse_dates = ['date'], lineterminator='\\n', encoding='latin-1')\n",
    "    df['date'] = pd.DatetimeIndex(df['date']).date\n",
    "    \n",
    "    # mean sentiment score per date\n",
    "    df_temp = (df[abs(df['compound'])>0.1].\n",
    "                  groupby('date').\n",
    "                  mean()[['compound']].\n",
    "                  reset_index()\n",
    "              )\n",
    "    # number of tweets per date\n",
    "    df_temp['compound_count'] = (df[abs(df['compound'])>0.1].\n",
    "                             groupby(['date']).\n",
    "                             count()['compound'].to_list())\n",
    "    # add keyword column\n",
    "    df_temp['keyword'] = keyword\n",
    "    # concatenate df of different keywords\n",
    "    sent_per_date = pd.concat([sent_per_date, df_temp], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec8c9f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "sent_per_date.to_csv('../shinyapp/data/sentiment_per_date.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0dc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>compound_count</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-0.025487</td>\n",
       "      <td>40</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.108270</td>\n",
       "      <td>63</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>-0.036004</td>\n",
       "      <td>53</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.087431</td>\n",
       "      <td>52</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>49</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>-0.009902</td>\n",
       "      <td>1173</td>\n",
       "      <td>macron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>-0.090024</td>\n",
       "      <td>1247</td>\n",
       "      <td>macron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>-0.049231</td>\n",
       "      <td>1179</td>\n",
       "      <td>macron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>-0.077883</td>\n",
       "      <td>926</td>\n",
       "      <td>macron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>-0.161761</td>\n",
       "      <td>901</td>\n",
       "      <td>macron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        date  compound  compound_count  keyword\n",
       "0             0  2022-01-01 -0.025487              40  ukraine\n",
       "1             1  2022-01-02  0.108270              63  ukraine\n",
       "2             2  2022-01-03 -0.036004              53  ukraine\n",
       "3             3  2022-01-04  0.087431              52  ukraine\n",
       "4             4  2022-01-05  0.091302              49  ukraine\n",
       "..          ...         ...       ...             ...      ...\n",
       "532         532  2022-05-20 -0.009902            1173   macron\n",
       "533         533  2022-05-21 -0.090024            1247   macron\n",
       "534         534  2022-05-22 -0.049231            1179   macron\n",
       "535         535  2022-05-23 -0.077883             926   macron\n",
       "536         536  2022-05-24 -0.161761             901   macron\n",
       "\n",
       "[537 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../shinyapp/data/sentiment_per_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deac8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 537 entries, 0 to 536\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   date            537 non-null    object \n",
      " 1   compound        537 non-null    float64\n",
      " 2   compound_count  537 non-null    int64  \n",
      " 3   keyword         537 non-null    object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 16.9+ KB\n"
     ]
    }
   ],
   "source": [
    "sent_per_dateper_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c5c1897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>compound_count</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-0.025487</td>\n",
       "      <td>40</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.108270</td>\n",
       "      <td>63</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>-0.036004</td>\n",
       "      <td>53</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.087431</td>\n",
       "      <td>52</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>49</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  compound  compound_count  keyword\n",
       "0  2022-01-01 -0.025487              40  ukraine\n",
       "1  2022-01-02  0.108270              63  ukraine\n",
       "2  2022-01-03 -0.036004              53  ukraine\n",
       "3  2022-01-04  0.087431              52  ukraine\n",
       "4  2022-01-05  0.091302              49  ukraine"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_per_date_per_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dda4d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>compound_count</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-0.025487</td>\n",
       "      <td>40</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.108270</td>\n",
       "      <td>63</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>-0.036004</td>\n",
       "      <td>53</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.087431</td>\n",
       "      <td>52</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>49</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>-0.039210</td>\n",
       "      <td>7314</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>7290</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>-0.034922</td>\n",
       "      <td>7400</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>-0.048117</td>\n",
       "      <td>7489</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>-0.077618</td>\n",
       "      <td>7554</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  compound  compound_count  keyword\n",
       "0   2022-01-01 -0.025487              40  ukraine\n",
       "1   2022-01-02  0.108270              63  ukraine\n",
       "2   2022-01-03 -0.036004              53  ukraine\n",
       "3   2022-01-04  0.087431              52  ukraine\n",
       "4   2022-01-05  0.091302              49  ukraine\n",
       "..         ...       ...             ...      ...\n",
       "56  2022-05-20 -0.039210            7314  ukraine\n",
       "57  2022-05-21 -0.013122            7290  ukraine\n",
       "58  2022-05-22 -0.034922            7400  ukraine\n",
       "59  2022-05-23 -0.048117            7489  ukraine\n",
       "60  2022-05-24 -0.077618            7554  ukraine\n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = 'ukraine'\n",
    "df_temp = (df[abs(df['compound'])>0.1].\n",
    "                  groupby(['date']).\n",
    "                  mean()[['compound']].\n",
    "                  reset_index()\n",
    "          )\n",
    "\n",
    "df_temp['compound_count'] = (df[abs(df['compound'])>0.1].\n",
    "                             groupby(['date']).\n",
    "                             count()['compound'].to_list())\n",
    "df_temp['keyword'] = keyword\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb474ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc6805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704a790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34151ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbed18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
